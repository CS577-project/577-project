{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptual Loss For Real Time Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该网络与原始版本的Style Transfer的套路是一样的，唯一的不同就是原始版本的style transfer是直接拿vgg-16，从一张噪音图开始，一方面比对content image，另一方面比对style image，不断调整噪音图，从而得到一张融合后的图。而Percept Loss For Real Time Transfer则是增加了一个auto encoder形状的网络，叫做transformation network，进原图出来预测图，这个预测图与原图在内容做比对，与风格图在风格上做比对。在训练的时候，有若干张内容图，只有一张风格图。这样就可以训练transformation network一边顾及到恢复原图，一边顾及到贴近特定的风格。  \n",
    "结果就是，一个transformation network就贴近一张风格图。这样一来，一张新的内容图进来以后，直接就可以推断出风格迁移后的图像。图像质量理论上跟原始版本style transfer不会有啥差异，只不过是可以提前训练好该模型，不像style transfer原始版本，每次都要训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，拿一系列内容图+一张风格图训练一个网络，并保存下来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\Anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from main import build_parser\n",
    "from train import network_train\n",
    "from test import network_test\n",
    "import os\n",
    "\n",
    "# 当前目录\n",
    "#current_directory = os.path.dirname(os.path.abspath(__file__))\n",
    "current_directory = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batchs=8, check_iter=100, content_layers=[15], content_weight=10.0, cropsize=None, cuda_device_no=0, imsize=256, lr=0.1, max_iter=15000, model_load_path=None, output='stylized.jpg', save_path='./trained_models/', style_layers=[3, 8, 15, 22], style_weight=20.0, test_content=None, train_content='e:\\\\workspace\\\\577-project\\\\PerceptualLossForRealTimeTransfer\\\\../Images/original/', train_flag=True, train_style='e:\\\\workspace\\\\577-project\\\\PerceptualLossForRealTimeTransfer\\\\../Images/style-images/candy.jpg', tv_weight=3.0, vgg_flag='vgg16')\n",
      "device:cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\Anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\Anaconda3\\envs\\pytorchgpu\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 20 12:54:22 2023: iteration: [0/15000/],\tcontent_loss: 0.23,\tstyle_loss: 0.52,\ttv_loss: 0.01,\ttotal_loss: 12.65,\t\n",
      "Mon Nov 20 12:55:30 2023: iteration: [100/15000/],\tcontent_loss: 11.00,\tstyle_loss: 15.31,\ttv_loss: 0.06,\ttotal_loss: 416.41,\t\n",
      "Mon Nov 20 12:56:39 2023: iteration: [200/15000/],\tcontent_loss: 11.62,\tstyle_loss: 11.24,\ttv_loss: 0.13,\ttotal_loss: 341.44,\t\n",
      "Mon Nov 20 12:57:45 2023: iteration: [300/15000/],\tcontent_loss: 10.64,\tstyle_loss: 9.87,\ttv_loss: 0.15,\ttotal_loss: 304.31,\t\n",
      "Mon Nov 20 12:58:51 2023: iteration: [400/15000/],\tcontent_loss: 10.40,\tstyle_loss: 8.86,\ttv_loss: 0.16,\ttotal_loss: 281.68,\t\n",
      "Mon Nov 20 12:59:57 2023: iteration: [500/15000/],\tcontent_loss: 10.63,\tstyle_loss: 7.83,\ttv_loss: 0.18,\ttotal_loss: 263.46,\t\n",
      "Mon Nov 20 13:01:03 2023: iteration: [600/15000/],\tcontent_loss: 10.89,\tstyle_loss: 6.96,\ttv_loss: 0.19,\ttotal_loss: 248.65,\t\n",
      "Mon Nov 20 13:02:09 2023: iteration: [700/15000/],\tcontent_loss: 11.04,\tstyle_loss: 6.30,\ttv_loss: 0.21,\ttotal_loss: 237.02,\t\n",
      "Mon Nov 20 13:03:15 2023: iteration: [800/15000/],\tcontent_loss: 11.12,\tstyle_loss: 5.77,\ttv_loss: 0.22,\ttotal_loss: 227.24,\t\n",
      "Mon Nov 20 13:04:21 2023: iteration: [900/15000/],\tcontent_loss: 11.13,\tstyle_loss: 5.43,\ttv_loss: 0.23,\ttotal_loss: 220.48,\t\n",
      "Mon Nov 20 13:05:27 2023: iteration: [1000/15000/],\tcontent_loss: 11.09,\tstyle_loss: 5.14,\ttv_loss: 0.23,\ttotal_loss: 214.50,\t\n",
      "Mon Nov 20 13:06:33 2023: iteration: [1100/15000/],\tcontent_loss: 11.03,\tstyle_loss: 4.93,\ttv_loss: 0.24,\ttotal_loss: 209.69,\t\n",
      "Mon Nov 20 13:07:40 2023: iteration: [1200/15000/],\tcontent_loss: 10.97,\tstyle_loss: 4.78,\ttv_loss: 0.25,\ttotal_loss: 206.08,\t\n",
      "Mon Nov 20 13:08:46 2023: iteration: [1300/15000/],\tcontent_loss: 10.89,\tstyle_loss: 4.64,\ttv_loss: 0.25,\ttotal_loss: 202.56,\t\n",
      "Mon Nov 20 13:09:52 2023: iteration: [1400/15000/],\tcontent_loss: 10.81,\tstyle_loss: 4.54,\ttv_loss: 0.25,\ttotal_loss: 199.62,\t\n",
      "Mon Nov 20 13:10:58 2023: iteration: [1500/15000/],\tcontent_loss: 10.75,\tstyle_loss: 4.44,\ttv_loss: 0.26,\ttotal_loss: 197.06,\t\n",
      "Mon Nov 20 13:12:04 2023: iteration: [1600/15000/],\tcontent_loss: 10.70,\tstyle_loss: 4.35,\ttv_loss: 0.26,\ttotal_loss: 194.77,\t\n",
      "Mon Nov 20 13:13:10 2023: iteration: [1700/15000/],\tcontent_loss: 10.61,\tstyle_loss: 4.27,\ttv_loss: 0.27,\ttotal_loss: 192.30,\t\n",
      "Mon Nov 20 13:14:16 2023: iteration: [1800/15000/],\tcontent_loss: 10.56,\tstyle_loss: 4.21,\ttv_loss: 0.27,\ttotal_loss: 190.56,\t\n",
      "Mon Nov 20 13:15:22 2023: iteration: [1900/15000/],\tcontent_loss: 10.46,\tstyle_loss: 4.12,\ttv_loss: 0.28,\ttotal_loss: 187.95,\t\n",
      "Mon Nov 20 13:16:28 2023: iteration: [2000/15000/],\tcontent_loss: 10.42,\tstyle_loss: 4.06,\ttv_loss: 0.28,\ttotal_loss: 186.33,\t\n",
      "Mon Nov 20 13:17:35 2023: iteration: [2100/15000/],\tcontent_loss: 10.35,\tstyle_loss: 4.00,\ttv_loss: 0.29,\ttotal_loss: 184.33,\t\n",
      "Mon Nov 20 13:18:41 2023: iteration: [2200/15000/],\tcontent_loss: 10.31,\tstyle_loss: 3.94,\ttv_loss: 0.30,\ttotal_loss: 182.76,\t\n",
      "Mon Nov 20 13:19:47 2023: iteration: [2300/15000/],\tcontent_loss: 10.25,\tstyle_loss: 3.88,\ttv_loss: 0.30,\ttotal_loss: 181.07,\t\n",
      "Mon Nov 20 13:20:53 2023: iteration: [2400/15000/],\tcontent_loss: 10.20,\tstyle_loss: 3.83,\ttv_loss: 0.31,\ttotal_loss: 179.59,\t\n",
      "Mon Nov 20 13:21:59 2023: iteration: [2500/15000/],\tcontent_loss: 10.16,\tstyle_loss: 3.77,\ttv_loss: 0.31,\ttotal_loss: 177.98,\t\n",
      "Mon Nov 20 13:23:05 2023: iteration: [2600/15000/],\tcontent_loss: 10.09,\tstyle_loss: 3.72,\ttv_loss: 0.31,\ttotal_loss: 176.33,\t\n",
      "Mon Nov 20 13:24:11 2023: iteration: [2700/15000/],\tcontent_loss: 10.06,\tstyle_loss: 3.70,\ttv_loss: 0.32,\ttotal_loss: 175.49,\t\n",
      "Mon Nov 20 13:25:17 2023: iteration: [2800/15000/],\tcontent_loss: 10.01,\tstyle_loss: 3.65,\ttv_loss: 0.32,\ttotal_loss: 174.20,\t\n",
      "Mon Nov 20 13:26:23 2023: iteration: [2900/15000/],\tcontent_loss: 9.95,\tstyle_loss: 3.61,\ttv_loss: 0.33,\ttotal_loss: 172.72,\t\n",
      "Mon Nov 20 13:27:30 2023: iteration: [3000/15000/],\tcontent_loss: 9.91,\tstyle_loss: 3.59,\ttv_loss: 0.33,\ttotal_loss: 171.85,\t\n",
      "Mon Nov 20 13:28:36 2023: iteration: [3100/15000/],\tcontent_loss: 9.89,\tstyle_loss: 3.56,\ttv_loss: 0.33,\ttotal_loss: 171.20,\t\n",
      "Mon Nov 20 13:29:42 2023: iteration: [3200/15000/],\tcontent_loss: 9.82,\tstyle_loss: 3.52,\ttv_loss: 0.34,\ttotal_loss: 169.71,\t\n",
      "Mon Nov 20 13:30:48 2023: iteration: [3300/15000/],\tcontent_loss: 9.82,\tstyle_loss: 3.51,\ttv_loss: 0.34,\ttotal_loss: 169.37,\t\n",
      "Mon Nov 20 13:31:54 2023: iteration: [3400/15000/],\tcontent_loss: 9.75,\tstyle_loss: 3.47,\ttv_loss: 0.34,\ttotal_loss: 167.92,\t\n",
      "Mon Nov 20 13:33:00 2023: iteration: [3500/15000/],\tcontent_loss: 9.76,\tstyle_loss: 3.47,\ttv_loss: 0.34,\ttotal_loss: 167.96,\t\n",
      "Mon Nov 20 13:34:06 2023: iteration: [3600/15000/],\tcontent_loss: 9.73,\tstyle_loss: 3.44,\ttv_loss: 0.34,\ttotal_loss: 167.04,\t\n",
      "Mon Nov 20 13:35:12 2023: iteration: [3700/15000/],\tcontent_loss: 9.71,\tstyle_loss: 3.43,\ttv_loss: 0.35,\ttotal_loss: 166.63,\t\n",
      "Mon Nov 20 13:36:18 2023: iteration: [3800/15000/],\tcontent_loss: 9.66,\tstyle_loss: 3.40,\ttv_loss: 0.35,\ttotal_loss: 165.65,\t\n",
      "Mon Nov 20 13:37:24 2023: iteration: [3900/15000/],\tcontent_loss: 9.63,\tstyle_loss: 3.38,\ttv_loss: 0.35,\ttotal_loss: 165.03,\t\n",
      "Mon Nov 20 13:38:30 2023: iteration: [4000/15000/],\tcontent_loss: 9.62,\tstyle_loss: 3.37,\ttv_loss: 0.35,\ttotal_loss: 164.67,\t\n",
      "Mon Nov 20 13:39:36 2023: iteration: [4100/15000/],\tcontent_loss: 9.59,\tstyle_loss: 3.35,\ttv_loss: 0.35,\ttotal_loss: 163.98,\t\n",
      "Mon Nov 20 13:40:43 2023: iteration: [4200/15000/],\tcontent_loss: 9.56,\tstyle_loss: 3.34,\ttv_loss: 0.36,\ttotal_loss: 163.48,\t\n",
      "Mon Nov 20 13:41:49 2023: iteration: [4300/15000/],\tcontent_loss: 9.52,\tstyle_loss: 3.32,\ttv_loss: 0.36,\ttotal_loss: 162.74,\t\n",
      "Mon Nov 20 13:42:55 2023: iteration: [4400/15000/],\tcontent_loss: 9.57,\tstyle_loss: 3.33,\ttv_loss: 0.36,\ttotal_loss: 163.40,\t\n",
      "Mon Nov 20 13:44:01 2023: iteration: [4500/15000/],\tcontent_loss: 9.48,\tstyle_loss: 3.29,\ttv_loss: 0.36,\ttotal_loss: 161.71,\t\n",
      "Mon Nov 20 13:45:07 2023: iteration: [4600/15000/],\tcontent_loss: 9.46,\tstyle_loss: 3.29,\ttv_loss: 0.36,\ttotal_loss: 161.59,\t\n",
      "Mon Nov 20 13:46:13 2023: iteration: [4700/15000/],\tcontent_loss: 9.46,\tstyle_loss: 3.28,\ttv_loss: 0.36,\ttotal_loss: 161.29,\t\n",
      "Mon Nov 20 13:47:19 2023: iteration: [4800/15000/],\tcontent_loss: 9.42,\tstyle_loss: 3.27,\ttv_loss: 0.37,\ttotal_loss: 160.64,\t\n",
      "Mon Nov 20 13:48:25 2023: iteration: [4900/15000/],\tcontent_loss: 9.43,\tstyle_loss: 3.26,\ttv_loss: 0.37,\ttotal_loss: 160.70,\t\n",
      "Mon Nov 20 13:49:31 2023: iteration: [5000/15000/],\tcontent_loss: 9.41,\tstyle_loss: 3.26,\ttv_loss: 0.37,\ttotal_loss: 160.38,\t\n",
      "Mon Nov 20 13:50:37 2023: iteration: [5100/15000/],\tcontent_loss: 9.37,\tstyle_loss: 3.24,\ttv_loss: 0.37,\ttotal_loss: 159.49,\t\n",
      "Mon Nov 20 13:51:43 2023: iteration: [5200/15000/],\tcontent_loss: 9.36,\tstyle_loss: 3.23,\ttv_loss: 0.37,\ttotal_loss: 159.36,\t\n",
      "Mon Nov 20 13:52:50 2023: iteration: [5300/15000/],\tcontent_loss: 9.33,\tstyle_loss: 3.22,\ttv_loss: 0.37,\ttotal_loss: 158.89,\t\n",
      "Mon Nov 20 13:53:56 2023: iteration: [5400/15000/],\tcontent_loss: 9.35,\tstyle_loss: 3.22,\ttv_loss: 0.37,\ttotal_loss: 159.09,\t\n",
      "Mon Nov 20 13:55:02 2023: iteration: [5500/15000/],\tcontent_loss: 9.31,\tstyle_loss: 3.20,\ttv_loss: 0.37,\ttotal_loss: 158.33,\t\n",
      "Mon Nov 20 13:56:08 2023: iteration: [5600/15000/],\tcontent_loss: 9.35,\tstyle_loss: 3.23,\ttv_loss: 0.37,\ttotal_loss: 159.21,\t\n",
      "Mon Nov 20 13:57:14 2023: iteration: [5700/15000/],\tcontent_loss: 9.30,\tstyle_loss: 3.19,\ttv_loss: 0.37,\ttotal_loss: 157.98,\t\n",
      "Mon Nov 20 13:58:20 2023: iteration: [5800/15000/],\tcontent_loss: 9.32,\tstyle_loss: 3.21,\ttv_loss: 0.37,\ttotal_loss: 158.42,\t\n",
      "Mon Nov 20 13:59:26 2023: iteration: [5900/15000/],\tcontent_loss: 9.28,\tstyle_loss: 3.18,\ttv_loss: 0.38,\ttotal_loss: 157.49,\t\n",
      "Mon Nov 20 14:00:32 2023: iteration: [6000/15000/],\tcontent_loss: 9.26,\tstyle_loss: 3.17,\ttv_loss: 0.38,\ttotal_loss: 157.16,\t\n",
      "Mon Nov 20 14:01:38 2023: iteration: [6100/15000/],\tcontent_loss: 9.21,\tstyle_loss: 3.17,\ttv_loss: 0.38,\ttotal_loss: 156.68,\t\n",
      "Mon Nov 20 14:02:44 2023: iteration: [6200/15000/],\tcontent_loss: 9.24,\tstyle_loss: 3.17,\ttv_loss: 0.38,\ttotal_loss: 156.91,\t\n",
      "Mon Nov 20 14:03:50 2023: iteration: [6300/15000/],\tcontent_loss: 9.25,\tstyle_loss: 3.17,\ttv_loss: 0.38,\ttotal_loss: 157.10,\t\n",
      "Mon Nov 20 14:04:57 2023: iteration: [6400/15000/],\tcontent_loss: 9.18,\tstyle_loss: 3.14,\ttv_loss: 0.38,\ttotal_loss: 155.81,\t\n",
      "Mon Nov 20 14:06:03 2023: iteration: [6500/15000/],\tcontent_loss: 9.20,\tstyle_loss: 3.14,\ttv_loss: 0.38,\ttotal_loss: 155.96,\t\n",
      "Mon Nov 20 14:07:09 2023: iteration: [6600/15000/],\tcontent_loss: 9.22,\tstyle_loss: 3.16,\ttv_loss: 0.38,\ttotal_loss: 156.45,\t\n",
      "Mon Nov 20 14:08:15 2023: iteration: [6700/15000/],\tcontent_loss: 9.13,\tstyle_loss: 3.12,\ttv_loss: 0.39,\ttotal_loss: 154.86,\t\n",
      "Mon Nov 20 14:09:22 2023: iteration: [6800/15000/],\tcontent_loss: 9.15,\tstyle_loss: 3.13,\ttv_loss: 0.39,\ttotal_loss: 155.23,\t\n",
      "Mon Nov 20 14:10:32 2023: iteration: [6900/15000/],\tcontent_loss: 9.15,\tstyle_loss: 3.13,\ttv_loss: 0.39,\ttotal_loss: 155.15,\t\n",
      "Mon Nov 20 14:11:42 2023: iteration: [7000/15000/],\tcontent_loss: 9.16,\tstyle_loss: 3.13,\ttv_loss: 0.39,\ttotal_loss: 155.40,\t\n",
      "Mon Nov 20 14:12:54 2023: iteration: [7100/15000/],\tcontent_loss: 9.13,\tstyle_loss: 3.12,\ttv_loss: 0.39,\ttotal_loss: 154.85,\t\n",
      "Mon Nov 20 14:14:06 2023: iteration: [7200/15000/],\tcontent_loss: 9.11,\tstyle_loss: 3.11,\ttv_loss: 0.39,\ttotal_loss: 154.40,\t\n",
      "Mon Nov 20 14:15:16 2023: iteration: [7300/15000/],\tcontent_loss: 9.12,\tstyle_loss: 3.11,\ttv_loss: 0.39,\ttotal_loss: 154.63,\t\n",
      "Mon Nov 20 14:16:26 2023: iteration: [7400/15000/],\tcontent_loss: 9.09,\tstyle_loss: 3.10,\ttv_loss: 0.39,\ttotal_loss: 153.98,\t\n",
      "Mon Nov 20 14:17:36 2023: iteration: [7500/15000/],\tcontent_loss: 9.09,\tstyle_loss: 3.10,\ttv_loss: 0.39,\ttotal_loss: 154.10,\t\n",
      "Mon Nov 20 14:18:46 2023: iteration: [7600/15000/],\tcontent_loss: 9.07,\tstyle_loss: 3.09,\ttv_loss: 0.39,\ttotal_loss: 153.61,\t\n",
      "Mon Nov 20 14:19:56 2023: iteration: [7700/15000/],\tcontent_loss: 9.14,\tstyle_loss: 3.12,\ttv_loss: 0.39,\ttotal_loss: 154.87,\t\n",
      "Mon Nov 20 14:21:07 2023: iteration: [7800/15000/],\tcontent_loss: 9.12,\tstyle_loss: 3.10,\ttv_loss: 0.39,\ttotal_loss: 154.35,\t\n",
      "Mon Nov 20 14:22:17 2023: iteration: [7900/15000/],\tcontent_loss: 9.03,\tstyle_loss: 3.08,\ttv_loss: 0.39,\ttotal_loss: 153.02,\t\n",
      "Mon Nov 20 14:23:27 2023: iteration: [8000/15000/],\tcontent_loss: 9.05,\tstyle_loss: 3.09,\ttv_loss: 0.39,\ttotal_loss: 153.41,\t\n",
      "Mon Nov 20 14:24:37 2023: iteration: [8100/15000/],\tcontent_loss: 9.02,\tstyle_loss: 3.07,\ttv_loss: 0.39,\ttotal_loss: 152.86,\t\n",
      "Mon Nov 20 14:25:48 2023: iteration: [8200/15000/],\tcontent_loss: 9.03,\tstyle_loss: 3.08,\ttv_loss: 0.40,\ttotal_loss: 153.01,\t\n",
      "Mon Nov 20 14:26:59 2023: iteration: [8300/15000/],\tcontent_loss: 9.03,\tstyle_loss: 3.07,\ttv_loss: 0.40,\ttotal_loss: 152.82,\t\n",
      "Mon Nov 20 14:28:10 2023: iteration: [8400/15000/],\tcontent_loss: 9.03,\tstyle_loss: 3.07,\ttv_loss: 0.40,\ttotal_loss: 152.95,\t\n",
      "Mon Nov 20 14:29:21 2023: iteration: [8500/15000/],\tcontent_loss: 9.04,\tstyle_loss: 3.07,\ttv_loss: 0.40,\ttotal_loss: 152.96,\t\n",
      "Mon Nov 20 14:30:29 2023: iteration: [8600/15000/],\tcontent_loss: 9.02,\tstyle_loss: 3.06,\ttv_loss: 0.40,\ttotal_loss: 152.64,\t\n",
      "Mon Nov 20 14:31:31 2023: iteration: [8700/15000/],\tcontent_loss: 9.01,\tstyle_loss: 3.06,\ttv_loss: 0.40,\ttotal_loss: 152.53,\t\n",
      "Mon Nov 20 14:32:34 2023: iteration: [8800/15000/],\tcontent_loss: 9.02,\tstyle_loss: 3.08,\ttv_loss: 0.40,\ttotal_loss: 152.91,\t\n",
      "Mon Nov 20 14:33:37 2023: iteration: [8900/15000/],\tcontent_loss: 8.99,\tstyle_loss: 3.05,\ttv_loss: 0.40,\ttotal_loss: 152.04,\t\n",
      "Mon Nov 20 14:35:06 2023: iteration: [9000/15000/],\tcontent_loss: 8.97,\tstyle_loss: 3.05,\ttv_loss: 0.40,\ttotal_loss: 151.91,\t\n",
      "Mon Nov 20 14:36:38 2023: iteration: [9100/15000/],\tcontent_loss: 8.97,\tstyle_loss: 3.05,\ttv_loss: 0.40,\ttotal_loss: 151.79,\t\n",
      "Mon Nov 20 14:38:12 2023: iteration: [9200/15000/],\tcontent_loss: 8.96,\tstyle_loss: 3.04,\ttv_loss: 0.40,\ttotal_loss: 151.62,\t\n",
      "Mon Nov 20 14:39:43 2023: iteration: [9300/15000/],\tcontent_loss: 8.94,\tstyle_loss: 3.04,\ttv_loss: 0.40,\ttotal_loss: 151.42,\t\n",
      "Mon Nov 20 14:41:06 2023: iteration: [9400/15000/],\tcontent_loss: 8.97,\tstyle_loss: 3.04,\ttv_loss: 0.40,\ttotal_loss: 151.71,\t\n",
      "Mon Nov 20 14:42:10 2023: iteration: [9500/15000/],\tcontent_loss: 8.97,\tstyle_loss: 3.05,\ttv_loss: 0.40,\ttotal_loss: 151.85,\t\n",
      "Mon Nov 20 14:43:19 2023: iteration: [9600/15000/],\tcontent_loss: 8.94,\tstyle_loss: 3.03,\ttv_loss: 0.40,\ttotal_loss: 151.29,\t\n",
      "Mon Nov 20 14:44:30 2023: iteration: [9700/15000/],\tcontent_loss: 8.96,\tstyle_loss: 3.03,\ttv_loss: 0.40,\ttotal_loss: 151.45,\t\n",
      "Mon Nov 20 14:45:40 2023: iteration: [9800/15000/],\tcontent_loss: 8.92,\tstyle_loss: 3.02,\ttv_loss: 0.41,\ttotal_loss: 150.95,\t\n",
      "Mon Nov 20 14:46:50 2023: iteration: [9900/15000/],\tcontent_loss: 8.93,\tstyle_loss: 3.03,\ttv_loss: 0.41,\ttotal_loss: 151.10,\t\n",
      "Mon Nov 20 14:48:00 2023: iteration: [10000/15000/],\tcontent_loss: 8.93,\tstyle_loss: 3.03,\ttv_loss: 0.41,\ttotal_loss: 151.02,\t\n",
      "Mon Nov 20 14:49:12 2023: iteration: [10100/15000/],\tcontent_loss: 8.91,\tstyle_loss: 3.02,\ttv_loss: 0.41,\ttotal_loss: 150.74,\t\n",
      "Mon Nov 20 14:50:21 2023: iteration: [10200/15000/],\tcontent_loss: 8.91,\tstyle_loss: 3.01,\ttv_loss: 0.41,\ttotal_loss: 150.53,\t\n",
      "Mon Nov 20 14:51:32 2023: iteration: [10300/15000/],\tcontent_loss: 8.90,\tstyle_loss: 3.02,\ttv_loss: 0.41,\ttotal_loss: 150.52,\t\n",
      "Mon Nov 20 14:52:43 2023: iteration: [10400/15000/],\tcontent_loss: 8.91,\tstyle_loss: 3.02,\ttv_loss: 0.41,\ttotal_loss: 150.66,\t\n",
      "Mon Nov 20 14:53:54 2023: iteration: [10500/15000/],\tcontent_loss: 8.88,\tstyle_loss: 3.01,\ttv_loss: 0.41,\ttotal_loss: 150.16,\t\n",
      "Mon Nov 20 14:55:06 2023: iteration: [10600/15000/],\tcontent_loss: 8.90,\tstyle_loss: 3.01,\ttv_loss: 0.41,\ttotal_loss: 150.48,\t\n",
      "Mon Nov 20 14:56:18 2023: iteration: [10700/15000/],\tcontent_loss: 8.90,\tstyle_loss: 3.01,\ttv_loss: 0.41,\ttotal_loss: 150.52,\t\n",
      "Mon Nov 20 14:57:30 2023: iteration: [10800/15000/],\tcontent_loss: 8.87,\tstyle_loss: 3.01,\ttv_loss: 0.41,\ttotal_loss: 150.05,\t\n",
      "Mon Nov 20 14:58:42 2023: iteration: [10900/15000/],\tcontent_loss: 8.89,\tstyle_loss: 3.01,\ttv_loss: 0.41,\ttotal_loss: 150.27,\t\n",
      "Mon Nov 20 14:59:54 2023: iteration: [11000/15000/],\tcontent_loss: 8.86,\tstyle_loss: 3.00,\ttv_loss: 0.41,\ttotal_loss: 149.76,\t\n",
      "Mon Nov 20 15:01:06 2023: iteration: [11100/15000/],\tcontent_loss: 8.87,\tstyle_loss: 3.00,\ttv_loss: 0.41,\ttotal_loss: 150.05,\t\n",
      "Mon Nov 20 15:02:17 2023: iteration: [11200/15000/],\tcontent_loss: 8.95,\tstyle_loss: 3.04,\ttv_loss: 0.41,\ttotal_loss: 151.47,\t\n",
      "Mon Nov 20 15:03:29 2023: iteration: [11300/15000/],\tcontent_loss: 8.84,\tstyle_loss: 2.99,\ttv_loss: 0.42,\ttotal_loss: 149.47,\t\n",
      "Mon Nov 20 15:04:44 2023: iteration: [11400/15000/],\tcontent_loss: 8.83,\tstyle_loss: 2.99,\ttv_loss: 0.42,\ttotal_loss: 149.34,\t\n",
      "Mon Nov 20 15:05:58 2023: iteration: [11500/15000/],\tcontent_loss: 8.84,\tstyle_loss: 2.99,\ttv_loss: 0.42,\ttotal_loss: 149.40,\t\n",
      "Mon Nov 20 15:07:09 2023: iteration: [11600/15000/],\tcontent_loss: 8.84,\tstyle_loss: 2.99,\ttv_loss: 0.42,\ttotal_loss: 149.37,\t\n",
      "Mon Nov 20 15:08:17 2023: iteration: [11700/15000/],\tcontent_loss: 8.84,\tstyle_loss: 2.99,\ttv_loss: 0.42,\ttotal_loss: 149.44,\t\n",
      "Mon Nov 20 15:09:20 2023: iteration: [11800/15000/],\tcontent_loss: 8.84,\tstyle_loss: 3.00,\ttv_loss: 0.42,\ttotal_loss: 149.54,\t\n",
      "Mon Nov 20 15:10:23 2023: iteration: [11900/15000/],\tcontent_loss: 8.85,\tstyle_loss: 2.99,\ttv_loss: 0.42,\ttotal_loss: 149.56,\t\n",
      "Mon Nov 20 15:11:27 2023: iteration: [12000/15000/],\tcontent_loss: 8.81,\tstyle_loss: 2.98,\ttv_loss: 0.42,\ttotal_loss: 148.97,\t\n",
      "Mon Nov 20 15:12:32 2023: iteration: [12100/15000/],\tcontent_loss: 8.86,\tstyle_loss: 2.99,\ttv_loss: 0.42,\ttotal_loss: 149.62,\t\n",
      "Mon Nov 20 15:13:41 2023: iteration: [12200/15000/],\tcontent_loss: 8.84,\tstyle_loss: 2.98,\ttv_loss: 0.42,\ttotal_loss: 149.33,\t\n",
      "Mon Nov 20 15:14:49 2023: iteration: [12300/15000/],\tcontent_loss: 8.84,\tstyle_loss: 2.99,\ttv_loss: 0.42,\ttotal_loss: 149.48,\t\n",
      "Mon Nov 20 15:15:58 2023: iteration: [12400/15000/],\tcontent_loss: 8.80,\tstyle_loss: 2.97,\ttv_loss: 0.42,\ttotal_loss: 148.63,\t\n",
      "Mon Nov 20 15:17:07 2023: iteration: [12500/15000/],\tcontent_loss: 8.81,\tstyle_loss: 2.98,\ttv_loss: 0.42,\ttotal_loss: 148.93,\t\n",
      "Mon Nov 20 15:18:15 2023: iteration: [12600/15000/],\tcontent_loss: 8.79,\tstyle_loss: 2.97,\ttv_loss: 0.42,\ttotal_loss: 148.52,\t\n",
      "Mon Nov 20 15:19:24 2023: iteration: [12700/15000/],\tcontent_loss: 8.82,\tstyle_loss: 2.98,\ttv_loss: 0.42,\ttotal_loss: 148.94,\t\n",
      "Mon Nov 20 15:20:26 2023: iteration: [12800/15000/],\tcontent_loss: 8.81,\tstyle_loss: 2.97,\ttv_loss: 0.42,\ttotal_loss: 148.81,\t\n",
      "Mon Nov 20 15:21:28 2023: iteration: [12900/15000/],\tcontent_loss: 8.78,\tstyle_loss: 2.97,\ttv_loss: 0.42,\ttotal_loss: 148.42,\t\n",
      "Mon Nov 20 15:22:30 2023: iteration: [13000/15000/],\tcontent_loss: 8.80,\tstyle_loss: 2.97,\ttv_loss: 0.42,\ttotal_loss: 148.74,\t\n",
      "Mon Nov 20 15:23:32 2023: iteration: [13100/15000/],\tcontent_loss: 8.79,\tstyle_loss: 2.97,\ttv_loss: 0.43,\ttotal_loss: 148.52,\t\n",
      "Mon Nov 20 15:24:34 2023: iteration: [13200/15000/],\tcontent_loss: 8.79,\tstyle_loss: 2.96,\ttv_loss: 0.43,\ttotal_loss: 148.44,\t\n",
      "Mon Nov 20 15:25:36 2023: iteration: [13300/15000/],\tcontent_loss: 8.77,\tstyle_loss: 2.97,\ttv_loss: 0.43,\ttotal_loss: 148.32,\t\n",
      "Mon Nov 20 15:26:37 2023: iteration: [13400/15000/],\tcontent_loss: 8.78,\tstyle_loss: 2.96,\ttv_loss: 0.43,\ttotal_loss: 148.35,\t\n",
      "Mon Nov 20 15:27:39 2023: iteration: [13500/15000/],\tcontent_loss: 8.74,\tstyle_loss: 2.95,\ttv_loss: 0.43,\ttotal_loss: 147.70,\t\n",
      "Mon Nov 20 15:28:41 2023: iteration: [13600/15000/],\tcontent_loss: 8.78,\tstyle_loss: 2.96,\ttv_loss: 0.43,\ttotal_loss: 148.34,\t\n",
      "Mon Nov 20 15:29:42 2023: iteration: [13700/15000/],\tcontent_loss: 8.76,\tstyle_loss: 2.96,\ttv_loss: 0.43,\ttotal_loss: 148.06,\t\n",
      "Mon Nov 20 15:30:45 2023: iteration: [13800/15000/],\tcontent_loss: 8.76,\tstyle_loss: 2.95,\ttv_loss: 0.43,\ttotal_loss: 147.95,\t\n",
      "Mon Nov 20 15:31:47 2023: iteration: [13900/15000/],\tcontent_loss: 8.73,\tstyle_loss: 2.95,\ttv_loss: 0.43,\ttotal_loss: 147.53,\t\n",
      "Mon Nov 20 15:32:50 2023: iteration: [14000/15000/],\tcontent_loss: 8.76,\tstyle_loss: 2.95,\ttv_loss: 0.43,\ttotal_loss: 147.96,\t\n",
      "Mon Nov 20 15:33:54 2023: iteration: [14100/15000/],\tcontent_loss: 8.74,\tstyle_loss: 2.95,\ttv_loss: 0.43,\ttotal_loss: 147.63,\t\n",
      "Mon Nov 20 15:34:55 2023: iteration: [14200/15000/],\tcontent_loss: 8.77,\tstyle_loss: 2.95,\ttv_loss: 0.43,\ttotal_loss: 148.06,\t\n",
      "Mon Nov 20 15:35:57 2023: iteration: [14300/15000/],\tcontent_loss: 8.76,\tstyle_loss: 2.95,\ttv_loss: 0.43,\ttotal_loss: 147.93,\t\n",
      "Mon Nov 20 15:37:01 2023: iteration: [14400/15000/],\tcontent_loss: 8.85,\tstyle_loss: 3.01,\ttv_loss: 0.43,\ttotal_loss: 150.03,\t\n",
      "Mon Nov 20 15:38:05 2023: iteration: [14500/15000/],\tcontent_loss: 8.77,\tstyle_loss: 2.95,\ttv_loss: 0.43,\ttotal_loss: 148.05,\t\n",
      "Mon Nov 20 15:39:07 2023: iteration: [14600/15000/],\tcontent_loss: 8.73,\tstyle_loss: 2.94,\ttv_loss: 0.43,\ttotal_loss: 147.38,\t\n",
      "Mon Nov 20 15:40:11 2023: iteration: [14700/15000/],\tcontent_loss: 8.74,\tstyle_loss: 2.94,\ttv_loss: 0.43,\ttotal_loss: 147.59,\t\n",
      "Mon Nov 20 15:41:14 2023: iteration: [14800/15000/],\tcontent_loss: 8.73,\tstyle_loss: 2.94,\ttv_loss: 0.43,\ttotal_loss: 147.50,\t\n",
      "Mon Nov 20 15:42:17 2023: iteration: [14900/15000/],\tcontent_loss: 8.72,\tstyle_loss: 2.94,\ttv_loss: 0.43,\ttotal_loss: 147.20,\t\n"
     ]
    }
   ],
   "source": [
    "# 训练模式\n",
    "\n",
    "parser = build_parser()\n",
    "content_imagedir = os.path.join(current_directory, \"../Images/original/\")\n",
    "style_imagepath = os.path.join(current_directory, \"../Images/style-images/candy.jpg\")\n",
    "custom_args = [\n",
    "    \"--train-flag\", \"True\",\n",
    "    \"--train-content\", content_imagedir,\n",
    "    \"--train-style\", style_imagepath,\n",
    "    \"--content-weight\", \"10\",\n",
    "    \"--style-weight\", \"20\",\n",
    "    \"--tv-weight\", \"3\",\n",
    "    \"--max-iter\", \"15000\"\n",
    "]\n",
    "args = parser.parse_args(custom_args)\n",
    "print(args)\n",
    "\n",
    "transform_network = network_train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在开始测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batchs=8, check_iter=100, content_layers=[15], content_weight=1.0, cropsize=None, cuda_device_no=0, imsize=256, lr=0.1, max_iter=15000, model_load_path='e:\\\\workspace\\\\577-project\\\\PerceptualLossForRealTimeTransfer\\\\trained_models/transform_network.pth', output='e:\\\\workspace\\\\577-project\\\\PerceptualLossForRealTimeTransfer\\\\../Images/styletransfer-output/HeadBaseTransfered.jpg', save_path='./trained_models/', style_layers=[3, 8, 15, 22], style_weight=30.0, test_content='e:\\\\workspace\\\\577-project\\\\PerceptualLossForRealTimeTransfer\\\\../Images/content-images/HeadBase.jpg', train_content=None, train_flag=False, train_style=None, tv_weight=1.0, vgg_flag='vgg16')\n",
      "device:cuda:0\n"
     ]
    }
   ],
   "source": [
    "parser = build_parser()\n",
    "model_path = os.path.join(current_directory, \"trained_models/transform_network.pth\")\n",
    "test_imagepath = os.path.join(current_directory, \"../Images/content-images/HeadBase.jpg\")\n",
    "output_imagepath = os.path.join(current_directory, \"../Images/styletransfer-output/HeadBaseTransfered.jpg\")\n",
    "custom_args = [\n",
    "    \"--train-flag\", \"False\",\n",
    "    \"--model-load-path\", model_path,\n",
    "    \"--test-content\", test_imagepath,\n",
    "    \"--output\", output_imagepath\n",
    "]\n",
    "\n",
    "args = parser.parse_args(custom_args)\n",
    "print(args)\n",
    "\n",
    "network_test(args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs577",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
